{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 11 – Training Deep Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercises in chapter 11._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing/Exploding Gradients Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier and He Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'serialize',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1e42d9f76c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1e42d9b6988>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 10s 184us/sample - loss: 1.2806 - accuracy: 0.6250 - val_loss: 0.8882 - val_accuracy: 0.7152\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.7954 - accuracy: 0.7374 - val_loss: 0.7135 - val_accuracy: 0.7648\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.6816 - accuracy: 0.7727 - val_loss: 0.6356 - val_accuracy: 0.7882\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 9s 169us/sample - loss: 0.6215 - accuracy: 0.7936 - val_loss: 0.5922 - val_accuracy: 0.8012\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 10s 177us/sample - loss: 0.5830 - accuracy: 0.8082 - val_loss: 0.5596 - val_accuracy: 0.8170\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.5553 - accuracy: 0.8156 - val_loss: 0.5339 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 10s 186us/sample - loss: 0.5340 - accuracy: 0.8220 - val_loss: 0.5157 - val_accuracy: 0.8312\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.5172 - accuracy: 0.8265 - val_loss: 0.5035 - val_accuracy: 0.8340\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 9s 171us/sample - loss: 0.5036 - accuracy: 0.8298 - val_loss: 0.4950 - val_accuracy: 0.8356\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 9s 171us/sample - loss: 0.4922 - accuracy: 0.8323 - val_loss: 0.4797 - val_accuracy: 0.8428\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try PReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 12s 219us/sample - loss: 1.3470 - accuracy: 0.6225 - val_loss: 0.9268 - val_accuracy: 0.7200\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 11s 198us/sample - loss: 0.8208 - accuracy: 0.7357 - val_loss: 0.7322 - val_accuracy: 0.7640\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.6972 - accuracy: 0.7697 - val_loss: 0.6494 - val_accuracy: 0.7868\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 11s 197us/sample - loss: 0.6332 - accuracy: 0.7903 - val_loss: 0.6027 - val_accuracy: 0.8024\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 11s 199us/sample - loss: 0.5918 - accuracy: 0.8050 - val_loss: 0.5674 - val_accuracy: 0.8138\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 0.5618 - accuracy: 0.8139 - val_loss: 0.5393 - val_accuracy: 0.8250\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.5391 - accuracy: 0.8215 - val_loss: 0.5203 - val_accuracy: 0.8306\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 10s 189us/sample - loss: 0.5212 - accuracy: 0.8250 - val_loss: 0.5070 - val_accuracy: 0.8332\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 11s 195us/sample - loss: 0.5067 - accuracy: 0.8289 - val_loss: 0.4971 - val_accuracy: 0.8330\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 11s 193us/sample - loss: 0.4944 - accuracy: 0.8321 - val_loss: 0.4811 - val_accuracy: 0.8420\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1e458b2da88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"elu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activation function was proposed in this [great paper](https://arxiv.org/pdf/1706.02515.pdf) by Günter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use ℓ<sub>1</sub> or ℓ<sub>2</sub> regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the SELU hyperparameters (`scale` and `alpha`) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: mean -0.00, std deviation 1.00\n",
      "Layer 100: mean 0.02, std deviation 0.96\n",
      "Layer 200: mean 0.01, std deviation 0.90\n",
      "Layer 300: mean -0.02, std deviation 0.92\n",
      "Layer 400: mean 0.05, std deviation 0.89\n",
      "Layer 500: mean 0.01, std deviation 0.93\n",
      "Layer 600: mean 0.02, std deviation 0.92\n",
      "Layer 700: mean -0.02, std deviation 0.90\n",
      "Layer 800: mean 0.05, std deviation 0.83\n",
      "Layer 900: mean 0.02, std deviation 1.00\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SELU is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x1e45eaba348>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"selu\",\n",
    "                   kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a neural net for Fashion MNIST with 100 hidden layers, using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
    "                             kernel_initializer=\"lecun_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 151s 3ms/sample - loss: 1.2023 - accuracy: 0.5325 - val_loss: 0.8044 - val_accuracy: 0.6928\n",
      "Epoch 2/5\n",
      "35328/55000 [==================>...........] - ETA: 46s - loss: 0.7644 - accuracy: 0.7160"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at what happens if we try to use the ReLU activation function instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great at all, we suffered from the vanishing/exploding gradients problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1.updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Keras optimizers accept `clipnorm` or `clipvalue` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing a Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the fashion MNIST training set in two:\n",
    "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
    "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
    "\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what's the final verdict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We got quite a bit of transfer: the error rate dropped by a factor of almost 4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(100 - 97.05) / (100 - 99.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adagrad(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamax Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 / (1 + steps / s)**c```\n",
    "* Keras uses `c=1` and `s = 1 / decay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "decay = 1e-4\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "epochs = np.arange(n_epochs)\n",
    "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
    "\n",
    "plt.plot(epochs, lrs,  \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Power Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 * 0.1**(epoch / s)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schedule function can take the current learning rate as a second argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(1 / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to update the learning rate at each iteration rather than at each epoch, you must write your own callback class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, s=40000):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # Note: the `batch` argument is reset at each epoch\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1 / s))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "lr0 = 0.01\n",
    "optimizer = keras.optimizers.Nadam(lr=lr0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "exp_decay = ExponentialDecay(s)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[exp_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = n_epochs * len(X_train) // 32\n",
    "steps = np.arange(n_steps)\n",
    "lrs = lr0 * 0.1**(steps / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
    "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise Constant Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.02, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\", color='b')\n",
    "plt.tick_params('y', colors='b')\n",
    "plt.gca().set_xlim(0, n_epochs - 1)\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
    "ax2.set_ylabel('Validation Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For piecewise constant scheduling, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "    values=[0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Cycle scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = len(X) // batch_size * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_1$ and $\\ell_2$ regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
    "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 20\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model with MC Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                           kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
